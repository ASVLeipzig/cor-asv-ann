{
  "git_url": "https://github.com/ASVLeipzig/cor-asv-ann",
  "version": "0.2.0",
  "tools": {
    "ocrd-cor-asv-ann-process": {
      "executable": "ocrd-cor-asv-ann-process",
      "categories": [
        "Text recognition and optimization"
      ],
      "steps": [
        "recognition/post-correction"
      ],
      "description": "Improve text annotation by character-level encoder-attention-decoder ANN model",
      "input_file_grp_cardinality": 1,
      "output_file_grp_cardinality": 1,
      "parameters": {
        "model_file": {
          "type": "string",
          "format": "uri",
          "content-type": "application/x-hdf;subtype=bag",
          "description": "path of h5py weight/config file for model trained with cor-asv-ann-train",
          "required": true,
          "cacheable": true
        },
        "textequiv_level": {
          "type": "string",
          "enum": ["line", "word", "glyph"],
          "default": "glyph",
          "description": "PAGE XML hierarchy level to read/write TextEquiv input/output on"
        },
        "charmap": {
          "type": "object",
          "default": {},
          "description": "mapping for input characters before passing to correction; can be used to adapt to character set mismatch between input and model (without relying on underspecification alone)"
        },
        "rejection_threshold": {
          "type": "number",
          "format": "float",
          "default": 0.5,
          "description": "minimum probability of the candidate corresponding to the input character in each hypothesis during beam search, helps balance precision/recall trade-off; set to 0 to disable rejection (max recall) or 1 to disable correction (max precision)"
        },
        "relative_beam_width": {
          "type": "number",
          "format": "float",
          "default": 0.2,
          "description": "minimum fraction of the best candidate's probability required to enter the beam in each hypothesis; controls the quality/performance trade-off"
        },
        "fixed_beam_width": {
          "type": "number",
          "format": "integer",
          "default": 15,
          "description": "maximum number of candidates allowed to enter the beam in each hypothesis; controls the quality/performance trade-off"
        },
        "fast_mode": {
          "type": "boolean",
          "default": false,
          "description": "decode greedy instead of beamed, with batches of parallel lines instead of parallel alternatives; also disables rejection and beam parameters; enable if performance is far more important than quality"
        }
      },
      "resources": [
        {
          "url": "https://git.informatik.uni-leipzig.de/ocr-d/cor-asv-ann-models/-/raw/master/s2s.dta19.Fraktur4.d2.w0512.adam.attention.stateless.variational-dropout.char.pretrained+retrained-conf.h5",
          "name": "s2s.dta19.Fraktur4.d2.w0512.adam.attention.stateless.variational-dropout.char.pretrained+retrained-conf.h5",
          "description": "LSTM sequence-to-sequence model of depth 2 width 512, initialised with weights from ocrd_keraslm, pretrained on 200k lines of clean text (input=output), both from DTA, then retrained on 19th century Fraktur texts (`GT4HistOCR/corpus/dta19` and OCR-D GT) as recognised by the Tesseract 4 model `script/Fraktur` (input=OCR with confidence and alternatives, output=GT)",
          "size": 53735168
        },
        {
          "url": "https://git.informatik.uni-leipzig.de/ocr-d/cor-asv-ann-models/-/raw/master/s2s.gt4histocr.s-ſ.d2.w0512.adam.attention.stateless.variational-dropout.char.transfer-lm.h5",
          "name": "s2s.gt4histocr.s-ſ.d2.w0512.adam.attention.stateless.variational-dropout.char.transfer-lm.h5",
          "description": "LSTM sequence-to-sequence model of depth 2 width 512, initialised with weights from ocrd_keraslm, pretrained on 200k lines of clean text (input=output), both from DTA, then retrained on 15-19th century Fraktur texts (GT4HistOCR and OCR-D GT) degraded by replacing `ſ` into `s` in the input (encouraging the network to learn its reconstruction)",
          "size": 53552788
        }
      ]
    },
    "ocrd-cor-asv-ann-evaluate": {
      "executable": "ocrd-cor-asv-ann-evaluate",
      "categories": [
        "Text recognition and optimization"
      ],
      "steps": [
        "evaluation/text"
      ],
      "description": "Align different textline annotations and compute distance",
      "input_file_grp_cardinality": -1,
      "output_file_grp_cardinality": 1,
      "parameters": {
        "match_on": {
          "type": "string",
          "enum": ["index", "id", "coords", "baseline"],
          "default": "id",
          "description": "Attribute to differentiate input annotations by: either `TextEquiv/@index` of the same TextLine and input file, or `TextLine/@id` (or `./Coords/@points` or `./Baseline/@points`) of input files across input fileGrps."
        },
        "metric": {
          "type": "string",
          "enum": ["Levenshtein-fast", "Levenshtein", "NFC", "NFKC", "historic_latin"],
          "default": "Levenshtein-fast",
          "description": "Distance metric to calculate and aggregate: `historic_latin` for GT level 1-3, `NFKC` for roughly GT level 2 (but including reduction of `ſ/s` and superscript numerals etc), `Levenshtein` for GT level 3 (or `Levenshtein-fast` for faster alignment - but using maximum sequence length instead of path length as CER denominator, and without confusion statistics)."
        },
        "gt_level": {
          "type": "number",
          "enum": [1, 2, 3],
          "default": 1,
          "description": "When `metric=historic_latin`, normalize and equate at this GT transcription level."
        },
        "confusion": {
          "type": "number",
          "format": "integer",
          "minimum": 0,
          "default": 0,
          "description": "Count edits and show that number of most frequent confusions (non-identity) in the end."
        },
        "histogram": {
          "type": "boolean",
          "default": false,
          "description": "Aggregate and show mutual character histograms."
        }
      }
    },
    "ocrd-cor-asv-ann-align": {
      "executable": "ocrd-cor-asv-ann-align",
      "categories": [
        "Text recognition and optimization"
      ],
      "steps": [
        "recognition/post-correction"
      ],
      "description": "Align different textline annotations and pick best",
      "input_file_grp_cardinality": [2, -1],
      "output_file_grp_cardinality": 1,
      "parameters": {
        "method": {
          "type": "string",
          "enum": ["majority", "confidence", "combined"],
          "default": "majority",
          "description": "decide by majority of OCR hypotheses, by highest confidence of OCRs or by a combination thereof"
        }
      }
    },
    "ocrd-cor-asv-ann-join": {
      "executable": "ocrd-cor-asv-ann-join",
      "categories": [
        "Text recognition and optimization"
      ],
      "steps": [
        "recognition/post-correction"
      ],
      "description": "Join different textline annotations by concatenation",
      "input_file_grp_cardinality": [2, -1],
      "output_file_grp_cardinality": 1,
      "parameters": {
        "add-filegrp-comments": {
          "type": "boolean",
          "default": false,
          "description": "set @comments of each TextEquiv to the fileGrp/@USE it came from"
        },
        "add-filegrp-index": {
          "type": "boolean",
          "default": false,
          "description": "set @index of each TextEquiv to the fileGrp index (zero based) it came from"
        },
        "match-on": {
          "type": "string",
          "enum": ["id", "coords", "baseline"],
          "default": "id",
          "description": "information to match lines on (element @id, Coords/@points, Baseline/@points)"
        }
      }
    },
    "ocrd-cor-asv-ann-mark": {
      "executable": "ocrd-cor-asv-ann-mark",
      "description": "mark words not found by a spellchecker",
      "steps": ["recognition/post-correction"],
      "categories": ["Text recognition and optimization"],
      "input_file_grp_cardinality": 1,
      "output_file_grp_cardinality": 1,
      "parameters": {
        "command": {
          "type": "string",
          "required": true,
          "description": "external tool to query word forms, e.g. 'hunspell -i utf-8 -d de_DE,en_US -w'"
        },
        "normalization": {
          "type": "object",
          "default": {},
          "description": "mapping of characters prior to spellcheck, e.g. {\"ſ\": \"s\", \"aͤ\": \"ä\"}"
        },
        "format": {
          "type": "string",
          "default": "conf",
          "description": "how unknown words should be marked; if 'conf', then writes @conf=0.123, otherwise writes that value into @comments"
        }
      }
    }
  }
}
